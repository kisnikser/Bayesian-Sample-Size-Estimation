\section{Введение}

Задача машинного обучения с учителем предполагает выбор предсказательной модели из некоторого параметрического семейства. Обычно такой выбор связан с некоторыми статистическими гипотезами, например, максимизацией некоторого функционала качества. Модель, которая соответствует этим статистическим гипотезам, называется \textit{адекватной} моделью \cite{bies2006genetic, cawley2010over, raschka2018model}.

При планировании вычислительного эксперимента требуется оценить минимальный размер выборки~--- количество объектов, необходимое для построения адекватной модели. Размер выборки, необходимый для построения адекватной модели прогнозирования, называется \textit{достаточным} \cite{byrd2012sample, figueroa2012predicting, balki2019sample}.

В работе рассматривается проблема определения достаточного размера выборки. Этой теме посвящено большое число работ. Используемые в них подходы можно разделить на статистические, байесовские и эвристические.

Одни из первых исследований по данной теме \cite{Adcock1988, Joseph1995} формулируют определенный статистический критерий, где связанный с данным критерием метод оценки размера выборки гарантирует достижение фиксированной статистической мощности с величиной ошибки первого рода, не превышающей заданного значения. К статистическим методам относятся метод множителей Лагранжа \cite{self1988power}, метод проверки отношения правдоподобия \cite{shieh2000power}, метод Вальда \cite{shieh2005power}. Статистические методы имеют ряд ограничений, которые связаны с их применением на практике. Они позволяют оценить размер выборки, исходя из предположений о распределении данных и информации о соответствии наблюдаемых величин предположениям нулевой гипотезы.

Байесовский подход тоже имеет место в данной проблеме. В работе \cite{Lindley1997} достаточный размер выборки определяется исходя из максимизации ожидаемой функции полезности. Она может включать в себя в явном виде функции распределения параметров и штрафы за увеличение размера выборки. Также в этой работе рассматриваются альтернативные подходы, основанные на ограничении некоторого критерия качества оценки параметров модели. Среди таких критериев можно выделить критерий средней апостериорной дисперсии APVC, критерий среднего покрытия ACC, критерий средней длины ALC и критерий эффективного объема выборки ESC. Эти критерии получили свое развитие в других работах, например, \cite{PhamGia1997} и \cite{Gelfand2002}. Спустя время, авторы \cite{Cao2009} провели теоретическое и практическое сравнение методов из \cite{Adcock1988, Joseph1995, Lindley1997}.

Авторы \cite{Brutti2014}, как и \cite{Pezeshk2008}, рассматривают различия между байесовским и частотным подходами при определении размера выборки. Также они предлагают робастные методы для байесовского подхода и приводят наглядные примеры для некоторых вероятностных моделей.

В работе \cite{Grabovoy2022} рассматриваются различные методы оценки размера выборки в обобщенных линейных моделях, включая статистические, эвристические и байесовские методы. Анализируются такие методы, как тест на множители Лагранжа, тест на отношение правдоподобия, статистика Вальда, кросс-валидация, бутстрап, критерий Кульбака-Лейблера, критерий средней апостериорной дисперсии, критерий среднего охвата, критерий средней длины и максимизация полезности. Авторы указывают на возможное развитие темы, которое заключается в поиске метода, сочетающего байесовский и статистический подходы для оценки размера выборки для недостаточного доступного размера выборки.

В \cite{MOTRENKO2014743} рассматривается метод определения размера выборки в логистической регрессии, использующий кросс-валидацию и дивергенцию Кульбака-Лейблера между апостериорными распределениями параметров модели на схожих подвыборках. Под схожими подвыборками понимают такие подвыборки, которые могут быть получены друг из друга добавлением, удалением или заменой одного объекта.

Генетический алгоритм \citep{Goldberg1988} используется с целью аппроксимации заданного набора функций. Он представляет собой процесс оптимизации популяции кандидатов (называемых особями), который эволюционирует в сторону лучших решений \citep{Mirjalili2019}. Каждая особь имеет набор характеристик (генов или фенотипов), которые могут изменяться в процессе эволюции. Изменение происходит с помощью операции кроссинговера или мутации. Эволюция начинается с случайной популяции, и каждое поколение рассматривается как основа для генерации следующего. Приспособленность особей измеряется в каждом поколении, и особи с высокой приспособленностью выбираются для создания нового поколения \citep{Kramer2017}. Алгоритм завершается после достижения максимального числа поколений или достижения удовлетворительных результатов. Таким образом, каждое новое поколение становится более приспособленным к окружающей среде.

В настоящей работе рассматриваются несколько подходов к определению достаточного размера выборки. Предлагается оценивать математическое ожидание и дисперсию функции правдоподобия на бутстрапированных подвыборках. Малое изменение этих величин при добавлении очередного объекта свидетельствует о достижении достаточного числа объектов в выборке. Доказывается корректность определения в модели линейной регрессии. Представленный метод легко использовать и на практике. Для этого предлагается подсчитывать значение функции ошибки, а не правдоподобия. Также в работе предлагается метод, который позволяет оценить достаточный размер выборки в случае, если данных объектов недостаточно. Используется генетический алгоритм для аппроксимации большого числа зависимостей функции ошибки от размера выборки на открытых датасетах с задачами регрессии и классификации.

Также в настоящей работе приводятся два подхода, основанных на расстоянии между апостериорными распределениями. Предлагается рассмотреть две подвыборки, вторая из которых получена добавлением одного объекта к первой. Апостериорные распределения параметров модели по этим подвыборкам оказываются близки, если размер выборки достаточен. Предлагается в качестве меры близости распределений использовать дивергенцию Кульбака-Лейблера \cite{MOTRENKO2014743}, а также функцию сравнения моделей s-score \cite{Aduenko2017}. Новизна данной работы заключается в доказательстве корректности предложенных методов. Корректность доказывается в вероятностой модели с нормальным апостериорным распределением параметров. Для модели линейной регрессии доказывается теорема о моментах предельного апостериорного распределения параметров.