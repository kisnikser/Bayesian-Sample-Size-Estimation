\section{Введение}

Задача машинного обучения с учителем предполагает выбор предсказательной модели из некоторого параметрического семейства. Обычно такой выбор связан с некоторыми статистическими гипотезами, например, максимизацией некоторого функционала качества. 
\begin{definition}
    Модель, которая соответствует этим статистическим гипотезам, называется \textbf{адекватной} моделью.
\end{definition}

При планировании вычислительного эксперимента требуется оценить минимальный размер выборки~--- количество объектов, необходимое для построения адекватной модели.

\begin{definition}
    Размер выборки, необходимый для построения адекватной модели прогнозирования, называется \textbf{достаточным}.
\end{definition}

В работе рассматривается проблема определения достаточного размера выборки. Этой теме посвящено большое число работ. Используемые в них подходы можно разделить на статистические, байесовские и эвристические.

Одни из первых статей по данной теме \cite{Adcock1988, Joseph1995} формулируют определенный статистический критерий, где связанный с данным критерием метод оценки размера выборки гарантирует достижение фиксированной статистической мощности с величиной ошибки первого рода, не превышающей заданного значения. Статистические методы имеют ряд ограничений, которые связаны с их применением на практике. Они позволяют оценить размер выборки, исходя из предположений о распределении данных и информации о соответствии наблюдаемых величин предположениям нулевой гипотезы.

Класс байесовских методов оценки размера выборки достаточно широк. 
В работе \cite{Lindley1997} достаточный размер выборки определяется исходя из максимизации ожидаемой функции полезности. Она может включать в себя в явном виде функции распределения параметров и штрафы за увеличение размера выборки. Также в этой работе рассматриваются альтернативные подходы, основанные на ограничении некоторого критерия качества оценки параметров модели. Среди таких критериев можно выделить критерий средней апостериорной дисперсии APVC, критерий среднего покрытия ACC, критерий срдней длины ALC и критерий эффективного объема выборки ESC. Эти критерии получили свое развитие в других работах, например, \cite{PhamGia1997} и \cite{Gelfand2002}. Спустя время, авторы \cite{Cao2009} провели теоретическое и практическое сравнение методов из \cite{Adcock1988, Joseph1995, Lindley1997}.

Авторы \cite{Brutti2014}, как и \cite{Pezeshk2008}, рассматривают различия между байесовским и частотным подходами при определении размера выборки. Также они предлагают робастные методы для байесовского подхода и приводят наглядные примеры для некоторых вероятностных моделей.

В работе \cite{Grabovoy2022} рассматриваются различные методы оценки размера выборки в обобщенных линейных моделях, включая статистические, эвристические и байесовские методы. Анализируются такие методы, как тест на множители Лагранжа, тест на отношение правдоподобия, статистика Вальда, кросс-валидация, бутстрап, критерий Кульбака-Лейблера, критерий средней апостериорной дисперсии, критерий среднего охвата, критерий средней длины и максимизация полезности. Авторы указывают на возможное развитие темы, которое заключается в поиске метода, сочетающего байесовский и статистический подходы для оценки размера выборки для недостаточного доступного размера выборки.

В \cite{MOTRENKO2014743} рассматривается метод определения размера выборки в логистической регрессии, использующий кросс-валидацию и дивергенцию Кульбака-Лейблера между апостериорными распределениями параметров модели на схожих подвыборках. Под схожими подвыборками понимают такие подвыборки, которые могут быть получены друг из друга добавлением, удалением или заменой одного объекта.

Настоящая работа использует генетический алгоритм \citep{Goldberg1988} с целью аппроксимации заданного набора функций. Генетический алгоритм представляет собой процесс оптимизации популяции кандидатов (называемых особями), который эволюционирует в сторону лучших решений \citep{Mirjalili2019}. Каждая особь имеет набор характеристик (генов или фенотипов), которые могут изменяться в процессе эволюции. Изменение происходит с помощью операции кроссинговера или мутации. Эволюция начинается с случайной популяции, и каждое поколение рассматривается как основа для генерации следующего. Приспособленность особей измеряется в каждом поколении, и особи с высокой приспособленностью выбираются для создания нового поколения \citep{Kramer2017}. Алгоритм завершается после достижения максимального числа поколений или достижения удовлетворительных результатов. Таким образом, каждое новое поколение становится более приспособленным к окружающей среде.